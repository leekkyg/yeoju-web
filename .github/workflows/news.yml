name: 여주 뉴스 수집

on:
  schedule:
    - cron: '0 0,6,12,18 * * *'
  workflow_dispatch:

jobs:
  collect-news:
    runs-on: ubuntu-latest
    
    steps:
      - name: 뉴스 수집
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          collect_and_save() {
            local name=$1
            local url=$2
            
            echo "=== $name 수집 ==="
            curl -s "$url" -A "Mozilla/5.0" -L --connect-timeout 10 -o rss.xml || true
            
            # 여러 패턴으로 제목 추출 시도
            grep -oP '(?<=<title><!\[CDATA\[)[^\]]+' rss.xml > titles.txt 2>/dev/null || true
            if [ ! -s titles.txt ]; then
              grep -oP '(?<=<title>)[^<]+' rss.xml > titles.txt 2>/dev/null || true
            fi
            
            # 링크 추출
            grep -oP '(?<=<link>)http[s]?://[^<]+' rss.xml > links.txt 2>/dev/null || true
            
            # 여주 관련 기사만 필터링
            grep -n "여주" titles.txt > filtered.txt 2>/dev/null || true
            
            count=$(wc -l < filtered.txt 2>/dev/null || echo "0")
            echo "$name: 여주 관련 $count개 기사 발견"
            
            # 저장
            while IFS=: read -r linenum title; do
              link=$(sed -n "${linenum}p" links.txt)
              if [ -n "$title" ] && [ -n "$link" ]; then
                title=$(echo "$title" | sed 's/"/\\"/g' | tr -d '\n\r')
                echo "저장: $title"
                curl -s -X POST "${SUPABASE_URL}/rest/v1/news" \
                  -H "apikey: ${SUPABASE_KEY}" \
                  -H "Authorization: Bearer ${SUPABASE_KEY}" \
                  -H "Content-Type: application/json" \
                  -H "Prefer: resolution=ignore-duplicates" \
                  -d "{\"title\": \"${title}\", \"source\": \"${name}\", \"link\": \"${link}\"}" || true
              fi
            done < filtered.txt
          }
          
          # 여주 지역 언론사들
          collect_and_save "경기일보" "https://www.kyeonggi.com/rss/S1N14.xml"
          collect_and_save "경인일보" "https://www.kyeongin.com/rss/allArticle.xml"
          collect_and_save "중부일보" "http://www.joongboo.com/rss/allArticle.xml"
          collect_and_save "기호일보" "http://www.kihoilbo.co.kr/rss/allArticle.xml"
          collect_and_save "인천일보" "http://www.incheonilbo.com/rss/allArticle.xml"
          collect_and_save "중도일보" "https://www.joongdo.co.kr/rss/allArticle.xml"
          collect_and_save "메트로신문" "https://www.metroseoul.co.kr/rss/allArticle.xml"
          collect_and_save "남한강뉴스" "http://www.news114.kr/rss/allArticle.xml"
          collect_and_save "미디어연합" "https://www.mediayonhap.com/rss/allArticle.xml"
          collect_and_save "세종신문" "https://www.sejongnewspaper.com/rss/allArticle.xml"
          collect_and_save "팔당유역신문" "https://www.hanaronews.kr/rss/allArticle.xml"
          collect_and_save "하나로신문" "https://www.hnrsm.com/rss/allArticle.xml"
          collect_and_save "전국매일신문" "https://www.jeonmae.co.kr/rss/allArticle.xml"
          collect_and_save "시사매거진" "https://www.sisamagazine.co.kr/rss/allArticle.xml"
          collect_and_save "경기뉴스통신" "https://www.kyungginews.com/rss/allArticle.xml"
          collect_and_save "새로나신문" "http://seronanews.com/rss/allArticle.xml"
          
          echo "=== 전체 완료 ==="