name: 여주 뉴스 수집

on:
  schedule:
    - cron: '0 0,6,12,18 * * *'
  workflow_dispatch:

jobs:
  collect-news:
    runs-on: ubuntu-latest
    
    steps:
      - name: 뉴스 수집
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          # 구글 뉴스 RSS 가져오기
          curl -s "https://news.google.com/rss/search?q=여주시&hl=ko&gl=KR&ceid=KR:ko" > rss.xml
          
          echo "=== RSS 내용 확인 ==="
          head -100 rss.xml
          
          # 제목과 링크 추출
          grep -oP '(?<=<title>).*?(?=</title>)' rss.xml | tail -n +2 | head -10 > titles.txt
          grep -oP '(?<=<link>)https://news.google.com[^<]*(?=</link>)' rss.xml | head -10 > links.txt
          
          echo "=== 추출된 제목 ==="
          cat titles.txt
          
          echo "=== 추출된 링크 ==="
          cat links.txt
          
          # 저장
          paste titles.txt links.txt | while IFS=$'\t' read -r title link; do
            if [ -n "$title" ] && [ -n "$link" ]; then
              echo "저장 중: $title"
              
              # 특수문자 처리
              title=$(echo "$title" | sed 's/"/\\"/g' | sed "s/'/\\'/g")
              
              curl -s -X POST "${SUPABASE_URL}/rest/v1/news" \
                -H "apikey: ${SUPABASE_KEY}" \
                -H "Authorization: Bearer ${SUPABASE_KEY}" \
                -H "Content-Type: application/json" \
                -H "Prefer: resolution=ignore-duplicates" \
                -d "{\"title\": \"${title}\", \"source\": \"구글뉴스\", \"link\": \"${link}\"}"
              
              echo " -> 완료"
            fi
          done
          
          echo "=== 전체 완료 ==="